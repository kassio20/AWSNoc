# SelectNOC IA - AWS Native AI Configuration
# Maximizando recursos de IA da AWS para análise inteligente de logs

# AWS AI Services Stack
aws_ai_stack:
  strategy: "aws_native_first"
  philosophy: "Leverage AWS AI ecosystem for optimal performance and cost"
  
  # Amazon Bedrock - Primary AI Engine
  bedrock:
    region_primary: "us-east-1"
    region_secondary: "us-west-2"
    
    models:
      # Claude-3 Sonnet - Principal para análise complexa
      log_analysis_primary:
        model_id: "anthropic.claude-3-sonnet-20240229-v1:0"
        use_case: "Complex log analysis, root cause identification"
        temperature: 0.1
        max_tokens: 4000
        streaming: true
        
      # Claude-3 Haiku - Para análises rápidas
      log_classification:
        model_id: "anthropic.claude-3-haiku-20240307-v1:0"
        use_case: "Fast log classification, severity detection"
        temperature: 0.05
        max_tokens: 1000
        streaming: false
        
      # Titan Text Premier - Para resumos e documentação
      incident_summarization:
        model_id: "amazon.titan-text-premier-v1:0"
        use_case: "Incident reports, executive summaries"
        temperature: 0.2
        max_tokens: 2000
        
      # Titan Embeddings - Para similaridade e clustering
      log_embeddings:
        model_id: "amazon.titan-embed-text-v1"
        use_case: "Log similarity, pattern clustering"
        dimensions: 1536
        
      # Jurassic-2 Ultra - Backup para análises específicas
      backup_analysis:
        model_id: "ai21.j2-ultra-v1"
        use_case: "Fallback for complex analysis"
        temperature: 0.15
        max_tokens: 3000
    
    # Prompt Templates Otimizados
    prompt_templates:
      log_analysis_expert: |
        Você é um especialista em infraestrutura AWS com 15 anos de experiência em troubleshooting.
        
        CONTEXTO:
        - Serviço: {service_name}
        - Ambiente: {environment}
        - Target Group: {target_group_name}
        - Status: {health_status}
        - Timestamp: {timestamp}
        
        LOGS PARA ANÁLISE:
        {log_entries}
        
        MÉTRICAS RELACIONADAS:
        {related_metrics}
        
        INSTRUÇÕES:
        1. Analise os logs identificando padrões de erro
        2. Classifique a severidade (CRITICAL/HIGH/MEDIUM/LOW)
        3. Identifique a causa raiz mais provável
        4. Liste serviços AWS potencialmente afetados
        5. Sugira próximos passos específicos
        6. Recomende runbooks relevantes
        
        FORMATO DE RESPOSTA:
        ```json
        {
          "severity": "HIGH",
          "confidence": 0.95,
          "root_cause": "Database connection pool exhaustion",
          "affected_services": ["ECS", "RDS"],
          "next_steps": ["Check RDS connections", "Scale ECS tasks"],
          "runbook": "rds-connection-troubleshooting",
          "timeline_estimate": "15-30 minutes"
        }
        ```
        
      severity_classifier: |
        Classifique a severidade deste log AWS:
        
        Log: {log_entry}
        Service: {service_type}
        
        Responda apenas com: CRITICAL, HIGH, MEDIUM ou LOW
        
      incident_correlator: |
        Analise estes eventos correlacionados:
        
        EVENTO 1: {event_1}
        EVENTO 2: {event_2}
        EVENTO 3: {event_3}
        
        Identifique se há correlação e sugira investigação.

  # Amazon SageMaker - ML Customizado
  sagemaker:
    region: "us-east-1"
    
    endpoints:
      # Detector de anomalias em métricas
      anomaly_detector:
        endpoint_name: "selectnoc-anomaly-detector-v1"
        instance_type: "ml.m5.large"
        algorithm: "randomcutforest"
        use_case: "CloudWatch metrics anomaly detection"
        
      # Classificador de logs customizado
      log_classifier:
        endpoint_name: "selectnoc-log-classifier-v1"
        instance_type: "ml.m5.xlarge"
        algorithm: "blazingtext"
        use_case: "AWS service-specific log classification"
        
      # Preditor de falhas
      failure_predictor:
        endpoint_name: "selectnoc-failure-predictor-v1"
        instance_type: "ml.m5.large"
        algorithm: "xgboost"
        use_case: "Predictive failure analysis"
    
    # Treinamento automatizado
    training:
      schedule: "weekly"
      data_source: "s3://selectnoc-training-data/"
      model_validation: "automated"
      
  # Amazon Comprehend - NLP Nativo
  comprehend:
    region: "us-east-1"
    
    features:
      # Análise de sentimento em logs de erro
      sentiment_analysis:
        enabled: true
        use_case: "Error log sentiment for severity indication"
        
      # Extração de entidades AWS
      entity_extraction:
        enabled: true
        custom_entities: ["aws_service", "instance_id", "error_code"]
        
      # Classificação customizada
      custom_classification:
        model_name: "selectnoc-aws-log-classifier"
        categories: ["network", "database", "compute", "storage"]
        
      # Detecção de tópicos
      topic_modeling:
        enabled: true
        use_case: "Automatic incident categorization"

  # Amazon Textract - Para análise de imagens/PDFs
  textract:
    region: "us-east-1"
    use_case: "Extract text from architecture diagrams, runbooks"
    
  # Amazon Translate - Multi-idioma
  translate:
    enabled: true
    target_languages: ["pt", "es", "fr"]
    use_case: "International customer support"

# AI Pipeline Orchestration
ai_pipeline:
  architecture: "event_driven"
  
  # Pipeline de análise em tempo real
  real_time_analysis:
    trigger: "cloudwatch_log_stream"
    steps:
      1:
        service: "bedrock"
        model: "claude-3-haiku"
        action: "quick_severity_classification"
        timeout: 5  # seconds
        
      2:
        service: "comprehend"
        action: "entity_extraction"
        parallel: true
        
      3:
        condition: "severity >= HIGH"
        service: "bedrock"
        model: "claude-3-sonnet"
        action: "detailed_analysis"
        timeout: 30
        
      4:
        service: "sagemaker"
        endpoint: "anomaly_detector"
        action: "correlation_analysis"
        
  # Pipeline de análise batch
  batch_analysis:
    schedule: "hourly"
    steps:
      1:
        service: "sagemaker"
        action: "pattern_discovery"
        
      2:
        service: "bedrock"
        model: "titan-text-premier"
        action: "trend_summarization"
        
      3:
        service: "comprehend"
        action: "topic_modeling"

# AWS Lambda Functions para IA
lambda_functions:
  # Pré-processamento de logs
  log_preprocessor:
    runtime: "python3.11"
    memory: 1024
    timeout: 60
    trigger: "cloudwatch_logs"
    ai_integration: "bedrock_streaming"
    
  # Correlacionador de eventos
  event_correlator:
    runtime: "python3.11"
    memory: 2048
    timeout: 300
    trigger: "eventbridge"
    ai_integration: "sagemaker_batch"
    
  # Gerador de relatórios
  report_generator:
    runtime: "python3.11"
    memory: 1024
    timeout: 600
    trigger: "scheduled"
    ai_integration: "bedrock_claude_sonnet"

# Vector Database para Embeddings
vector_database:
  service: "opensearch_serverless"
  collection: "selectnoc-log-embeddings"
  
  configuration:
    dimensions: 1536  # Titan embeddings
    similarity_metric: "cosine"
    indexing: "hnsw"
    
  use_cases:
    - "Similar incident lookup"
    - "Knowledge base search"
    - "Pattern matching"

# Knowledge Base com Amazon Bedrock
knowledge_base:
  service: "bedrock_knowledge_base"
  
  data_sources:
    aws_documentation:
      source: "s3://selectnoc-kb/aws-docs/"
      type: "documentation"
      
    runbooks:
      source: "s3://selectnoc-kb/runbooks/"
      type: "procedures"
      
    incident_history:
      source: "s3://selectnoc-kb/incidents/"
      type: "historical_data"
      
  retrieval:
    model: "titan-embed-text-v1"
    max_results: 10
    confidence_threshold: 0.7

# AI Cost Optimization
cost_optimization:
  bedrock:
    # Model selection baseada em complexidade
    smart_routing:
      simple_queries: "claude-3-haiku"  # Mais barato
      complex_analysis: "claude-3-sonnet"  # Quando necessário
      
    # Caching inteligente
    response_caching:
      enabled: true
      ttl: 3600  # 1 hora
      cache_key: "log_pattern_hash"
      
    # Batch processing
    batching:
      enabled: true
      batch_size: 10
      max_wait_time: 30  # seconds
      
  sagemaker:
    # Auto-scaling de endpoints
    auto_scaling:
      enabled: true
      min_capacity: 1
      max_capacity: 10
      target_cpu: 70
      
    # Endpoint management
    scheduled_scaling:
      business_hours: "scale_up"
      off_hours: "scale_down"
      weekend: "minimum"

# AI Monitoring e Performance
ai_monitoring:
  bedrock_metrics:
    - "InvocationsCount"
    - "InvocationLatency"
    - "InvocationErrors"
    - "TokenCount"
    
  sagemaker_metrics:
    - "ModelLatency"
    - "InvocationsPerInstance"
    - "InvocationErrors"
    
  custom_metrics:
    - "ai_accuracy_score"
    - "false_positive_rate"
    - "customer_satisfaction"
    
  alerts:
    high_latency: "> 10 seconds"
    error_rate: "> 5%"
    cost_spike: "> $100/hour"

# A/B Testing para IA
ab_testing:
  enabled: true
  
  experiments:
    model_comparison:
      control: "claude-3-haiku"
      variant: "claude-3-sonnet"
      metric: "accuracy"
      traffic_split: "90/10"
      
    prompt_optimization:
      variations: ["prompt_v1", "prompt_v2", "prompt_v3"]
      metric: "response_quality"
      
# Compliance e Segurança
ai_security:
  data_encryption:
    in_transit: "TLS-1.3"
    at_rest: "KMS"
    
  access_control:
    bedrock: "iam_roles"
    sagemaker: "vpc_endpoints"
    
  audit_logging:
    all_ai_calls: true
    response_logging: false  # Privacy
    
  data_residency:
    configurable: true
    default_region: "us-east-1"

